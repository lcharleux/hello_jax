{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## La promesse de Jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Jax promet de pouvoir écrire du code Python et de le déployer sur des plateformes CPU, GPU et TPU-Google sans efforts de traduction particuliers. Il permet aussi de faire des opérations (transformations) assez inédites comme la dérivation automatique des fonctions par rapport à leurs arguments ce qui constitue en soit un game changer pour l'IA et bien d'autres domaines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Le monde de Jax\n",
    "\n",
    "Avec des pincettes énormes, on pourrait résumer le monde de Jax à des données sous forme de **tenseurs** qui sont manipulées par des **fonctions pures** auxquelles on applique des **transformations**. \n",
    "Dans les nuances à apporter, il faut noter les données tensorielle sont agencées sous forme de ***pytrees*** ce qui une idées extrêmement puissante à elle seule, même si ce n'est pas ce qui saute aux yeux quand on début Jax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Des fonctions pures ?\n",
    "\n",
    "Dans Jax, la pureté des fonctions est un sujet qui revient souvent. Une fonction pure est une fonction qui n'a pas d'effets de bords. \n",
    "Elle n'utilise donc pas l'infinité de bidouilles que Python autorise. \n",
    "Dans les grandes lignes, les sorties d'une fonction doivent dépendre de manière déterministe de ses arguments et uniquement d'eux. \n",
    "Cela interdit notamment l'usage de variables globales (enfin, on verra que c'est plus subtile) et aussi de modifier dynamiquement ses propres arguments comme on le ferait souvent en *C*.\n",
    "Si on pense *C* justement, on peut se dire cette approche est antinomique avec l'économie de mémoire et la performance en général, en fait oui et non. \n",
    "Jax impose cette contrainte car il va voir les fonctions comme des scripts à interpréter dans son langage (voir **jaxpr**) et à traduire dans un langage dédié à la plateforme cible.\n",
    "L'optimisation au sens ou la verrait en C n'a donc pas lieu d'être. \n",
    "Le but de la pureté est avant tout de lever toute ambiguïté sur le fonctionnement interne de la fonction et de pouvoir y tracer le chemin de l'information.\n",
    "Il faut donc voir les fonctions comme des tuyaux dans lesquels le flux de données passe et la pureté indique juste que ces derniers ne doivent pas fuir ni laisser entrer des choses du milieu extérieur.\n",
    "\n",
    "Voici un petit exemple de fonction pure et de la manière sont Jax la comprend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import time\n",
    "\n",
    "\n",
    "def dumb_pure_func(x):\n",
    "    b = x + 3\n",
    "    c = b**2\n",
    "    return c\n",
    "\n",
    "\n",
    "dumb_pure_func(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "jax.make_jaxpr(dumb_pure_func)(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Jax est donc capable de comprendre le fonctionnement de la fonction est de la traduire par un bout de code dans son langage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Les transformations\n",
    "\n",
    "Imaginons qu'on travaille sur la fonction suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def myfunc(x, a=1, b=1, c=1):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "\n",
    "jax.make_jaxpr(myfunc)(3, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunc(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Vectoriser avec `vmap`\n",
    "\n",
    "On peut vectoriser par rapport à un axe par exemple avec vmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmyfunc = jax.vmap(myfunc, in_axes=(0, None, None, None))\n",
    "xa = jnp.linspace(0.0, 5.0, 6)\n",
    "vmyfunc(xa, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Mais on peut faire des structure bien plus complexes en combinant plusieurs transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmyfunc2 = jax.vmap(vmyfunc, in_axes=(None, 0, None, None))\n",
    "aa = jnp.linspace(0.0, 1.0, 3)\n",
    "vmyfunc2(xa, aa, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Le potentiel est énorme car on peut soit vectoriser en plusieurs strates ou aussi le faire d'un coup en jouant sur les axes selon les besoins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Compiler avec `jit`\n",
    "\n",
    "Il est possible de compiler tout ou partie du code avec `jit`. La compilation va coûter quelques milisecondes et permettre une execution optimisée par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne = 100\n",
    "xa = jnp.linspace(0.0, 5.0, 6000)\n",
    "aa = jnp.linspace(0.0, 1.0, 3000)\n",
    "t0 = time.time()\n",
    "for e in range(Ne):\n",
    "    val = vmyfunc2(xa, aa, 1, 1)\n",
    "    val.block_until_ready()\n",
    "t1 = time.time()\n",
    "dt0 = (t1 - t0) / Ne\n",
    "print(f\"Exectution took {dt0*1.e3:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvmyfunc2 = jax.jit(vmyfunc2)\n",
    "t0 = time.time()\n",
    "val = jvmyfunc2(xa, aa, 1, 1)\n",
    "val.block_until_ready()\n",
    "t1 = time.time()\n",
    "dt1 = t1 - t0\n",
    "print(f\"Compilation + first execution took {dt1*1.e3:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "for e in range(Ne):\n",
    "    val = jvmyfunc2(xa, aa, 1, 1)\n",
    "    val.block_until_ready()\n",
    "t1 = time.time()\n",
    "dt2 = (t1 - t0) / Ne\n",
    "print(f\"Second execution took {dt2*1.e3:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "On a donc gagné du temps avec le jit et ce malgré le fait que notre fonction est très simple et donc très optimisée à la base. Cette tendance sera amplifiée sur des calculs lourds sur GPU/TPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Autres transformations\n",
    "\n",
    "Les autres transformations ne sont pas cruciales maintenant alors je les passe sous couvert. Mais elles sont ultra intéressantes dans d'autres cas, surtout `grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Liste non exhaustive des limitations de Jax\n",
    "\n",
    "Forcément, cette belle promesse vient avec pas mal de limitations.\n",
    "\n",
    "### Les structures de contrôle\n",
    "\n",
    "On commence par une des plus agacentes au début, les structures de contrôle. Fini les `if`, `for`et `while`.\n",
    "\n",
    "![](https://media1.tenor.com/m/-mkYatTHWB0AAAAC/why-whyy.gif)\n",
    "\n",
    "En fait, ces dernières ne sont pas claires dans leurs buts et peuvent correspondre à plusieurs objectifs. Jax fournit donc des outils de remplacements qui ne manqueront pas de vous énerver (parfois). A titre d'exemple, `for`sera remplacée alternativement selon les buts par `vmap`, `scan`, `where`, `lax.fori_loop` ou pourra rester `for` dans ces bien choisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### L'allocation dynamique de mémoire\n",
    "\n",
    "Dans le monde de jax, il est interdit d'allouer dynamiquement de la mémoire, par exemple en créant des array de taille inconnue à la compilation. Cela ne manquera pas de vous créer des frustrations. On verra aussi qu'il est possible de trouver des compromis sur ce point. Le chapitre des *sharp bits* et globalement toutes les prises de parole de JakeVPD et Patrick Kidger mérite d'être lues pour comprendre la parole sainte à ce sujet.\n",
    "\n",
    "Exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_func_allocating_memory(n):\n",
    "    a = jnp.arange(n)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.make_jaxpr(dumb_func_allocating_memory)(2) # Uncommment to see the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "ConcretizationTypeError                   Traceback (most recent call last)\n",
    "Cell In[11], line 1\n",
    "----> 1 jax.make_jaxpr(dumb_func_allocating_memory)(2)\n",
    "\n",
    "    [... skipping hidden 14 frame]\n",
    "\n",
    "Cell In[10], line 2, in dumb_func_allocating_memory(n)\n",
    "      1 def dumb_func_allocating_memory(n):\n",
    "----> 2     a = jnp.arange(n)\n",
    "      3     return a\n",
    "\n",
    "File ~/miniforge3/envs/science/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:5947, in arange(start, stop, step, dtype, device, out_sharding)\n",
    "   5945 if sharding is None or not sharding._is_concrete:\n",
    "   5946   assert sharding is None or isinstance(sharding, NamedSharding)\n",
    "-> 5947   return _arange(start, stop=stop, step=step, dtype=dtype,\n",
    "   5948                  out_sharding=sharding)\n",
    "   5949 else:\n",
    "   5950   output = _arange(start, stop=stop, step=step, dtype=dtype)\n",
    "\n",
    "File ~/miniforge3/envs/science/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:5962, in _arange(start, stop, step, dtype, out_sharding)\n",
    "   5960 util.check_arraylike(\"arange\", start)\n",
    "   5961 if stop is None and step is None:\n",
    "-> 5962   start = core.concrete_or_error(None, start, \"It arose in the jnp.arange argument 'stop'\")\n",
    "   5963 else:\n",
    "   5964   start = core.concrete_or_error(None, start, \"It arose in the jnp.arange argument 'start'\")\n",
    "\n",
    "File ~/miniforge3/envs/science/lib/python3.12/site-packages/jax/_src/core.py:1847, in concrete_or_error(force, val, context)\n",
    "   1845 maybe_concrete = val.to_concrete_value()\n",
    "   1846 if maybe_concrete is None:\n",
    "-> 1847   raise ConcretizationTypeError(val, context)\n",
    "   1848 else:\n",
    "   1849   return force(maybe_concrete)\n",
    "\n",
    "ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: traced array with shape int32[]\n",
    "It arose in the jnp.arange argument 'stop'\n",
    "The error occurred while tracing the function dumb_func_allocating_memory at /var/folders/67/hblp6z8n36ldk_9_bl9g80kh0000gn/T/ipykernel_50677/3347747001.py:1 for jit. This concrete value was not available in Python because it depends on the value of the argument n.\n",
    "\n",
    "See https://docs.jax.dev/en/latest/errors.html#jax.errors.ConcretizationTypeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Frustration, colère ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Dans un tel, cas il faut généralement se demander si on a vraiment besoin que `n`soit dynamique. Si c'est vraiment le cas, alors on peut le rendre statique (au sens jax) en spécifiant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_dumb_function_allocating_memory(n):\n",
    "    def dumb_func_allocating_memory2(a):\n",
    "        x = a * jnp.arange(n)\n",
    "        return x\n",
    "\n",
    "    return dumb_func_allocating_memory2\n",
    "\n",
    "\n",
    "dfam = jax.jit(make_dumb_function_allocating_memory(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.make_jaxpr(dfam)(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
