{"version":"1","records":[{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/intro-to-jax","position":0},{"hierarchy":{"lvl1":"Introduction"},"content":"","type":"content","url":"/intro-to-jax","position":1},{"hierarchy":{"lvl1":"Introduction","lvl2":"La promesse de Jax"},"type":"lvl2","url":"/intro-to-jax#la-promesse-de-jax","position":2},{"hierarchy":{"lvl1":"Introduction","lvl2":"La promesse de Jax"},"content":"\n\nJax promet de pouvoir écrire du code Python et de le déployer sur des plateformes CPU, GPU et TPU-Google sans efforts de traduction particuliers. Il permet aussi de faire des opérations (transformations) assez inédites comme la dérivation automatique des fonctions par rapport à leurs arguments ce qui constitue en soit un game changer pour l’IA et bien d’autres domaines.\n\n","type":"content","url":"/intro-to-jax#la-promesse-de-jax","position":3},{"hierarchy":{"lvl1":"Introduction","lvl2":"Le monde de Jax"},"type":"lvl2","url":"/intro-to-jax#le-monde-de-jax","position":4},{"hierarchy":{"lvl1":"Introduction","lvl2":"Le monde de Jax"},"content":"Avec des pincettes énormes, on pourrait résumer le monde de Jax à des données sous forme de tenseurs qui sont manipulées par des fonctions pures auxquelles on applique des transformations.\nDans les nuances à apporter, il faut noter les données tensorielle sont agencées sous forme de pytrees ce qui une idées extrêmement puissante à elle seule, même si ce n’est pas ce qui saute aux yeux quand on début Jax.\n\n","type":"content","url":"/intro-to-jax#le-monde-de-jax","position":5},{"hierarchy":{"lvl1":"Introduction","lvl2":"Des fonctions pures ?"},"type":"lvl2","url":"/intro-to-jax#des-fonctions-pures","position":6},{"hierarchy":{"lvl1":"Introduction","lvl2":"Des fonctions pures ?"},"content":"Dans Jax, la pureté des fonctions est un sujet qui revient souvent. Une fonction pure est une fonction qui n’a pas d’effets de bords.\nElle n’utilise donc pas l’infinité de bidouilles que Python autorise.\nDans les grandes lignes, les sorties d’une fonction doivent dépendre de manière déterministe de ses arguments et uniquement d’eux.\nCela interdit notamment l’usage de variables globales (enfin, on verra que c’est plus subtile) et aussi de modifier dynamiquement ses propres arguments comme on le ferait souvent en C.\nSi on pense C justement, on peut se dire cette approche est antinomique avec l’économie de mémoire et la performance en général, en fait oui et non.\nJax impose cette contrainte car il va voir les fonctions comme des scripts à interpréter dans son langage (voir jaxpr) et à traduire dans un langage dédié à la plateforme cible.\nL’optimisation au sens ou la verrait en C n’a donc pas lieu d’être.\nLe but de la pureté est avant tout de lever toute ambiguïté sur le fonctionnement interne de la fonction et de pouvoir y tracer le chemin de l’information.\nIl faut donc voir les fonctions comme des tuyaux dans lesquels le flux de données passe et la pureté indique juste que ces derniers ne doivent pas fuir ni laisser entrer des choses du milieu extérieur.\n\nVoici un petit exemple de fonction pure et de la manière sont Jax la comprend:\n\nimport jax\nfrom jax import numpy as jnp\nimport time\n\n\ndef dumb_pure_func(x):\n    b = x + 3\n    c = b**2\n    return c\n\n\ndumb_pure_func(3)\n\njax.make_jaxpr(dumb_pure_func)(2)\n\nJax est donc capable de comprendre le fonctionnement de la fonction est de la traduire par un bout de code dans son langage.\n\n","type":"content","url":"/intro-to-jax#des-fonctions-pures","position":7},{"hierarchy":{"lvl1":"Introduction","lvl2":"Les transformations"},"type":"lvl2","url":"/intro-to-jax#les-transformations","position":8},{"hierarchy":{"lvl1":"Introduction","lvl2":"Les transformations"},"content":"Imaginons qu’on travaille sur la fonction suivante:\n\ndef myfunc(x, a=1, b=1, c=1):\n    return a * x**2 + b * x + c\n\n\njax.make_jaxpr(myfunc)(3, 1, 1, 1)\n\nmyfunc(5)\n\n","type":"content","url":"/intro-to-jax#les-transformations","position":9},{"hierarchy":{"lvl1":"Introduction","lvl3":"Vectoriser avec vmap","lvl2":"Les transformations"},"type":"lvl3","url":"/intro-to-jax#vectoriser-avec-vmap","position":10},{"hierarchy":{"lvl1":"Introduction","lvl3":"Vectoriser avec vmap","lvl2":"Les transformations"},"content":"On peut vectoriser par rapport à un axe par exemple avec vmap.\n\nvmyfunc = jax.vmap(myfunc, in_axes=(0, None, None, None))\nxa = jnp.linspace(0.0, 5.0, 6)\nvmyfunc(xa, 1, 1, 1)\n\nMais on peut faire des structure bien plus complexes en combinant plusieurs transformations:\n\nvmyfunc2 = jax.vmap(vmyfunc, in_axes=(None, 0, None, None))\naa = jnp.linspace(0.0, 1.0, 3)\nvmyfunc2(xa, aa, 1, 1)\n\nLe potentiel est énorme car on peut soit vectoriser en plusieurs strates ou aussi le faire d’un coup en jouant sur les axes selon les besoins.\n\n","type":"content","url":"/intro-to-jax#vectoriser-avec-vmap","position":11},{"hierarchy":{"lvl1":"Introduction","lvl3":"Compiler avec jit","lvl2":"Les transformations"},"type":"lvl3","url":"/intro-to-jax#compiler-avec-jit","position":12},{"hierarchy":{"lvl1":"Introduction","lvl3":"Compiler avec jit","lvl2":"Les transformations"},"content":"Il est possible de compiler tout ou partie du code avec jit. La compilation va coûter quelques milisecondes et permettre une execution optimisée par la suite.\n\nNe = 100\nxa = jnp.linspace(0.0, 5.0, 6000)\naa = jnp.linspace(0.0, 1.0, 3000)\nt0 = time.time()\nfor e in range(Ne):\n    val = vmyfunc2(xa, aa, 1, 1)\n    val.block_until_ready()\nt1 = time.time()\ndt0 = (t1 - t0) / Ne\nprint(f\"Exectution took {dt0*1.e3:.2f} ms\")\n\njvmyfunc2 = jax.jit(vmyfunc2)\nt0 = time.time()\nval = jvmyfunc2(xa, aa, 1, 1)\nval.block_until_ready()\nt1 = time.time()\ndt1 = t1 - t0\nprint(f\"Compilation + first execution took {dt1*1.e3:.2f} ms\")\n\nt0 = time.time()\nfor e in range(Ne):\n    val = jvmyfunc2(xa, aa, 1, 1)\n    val.block_until_ready()\nt1 = time.time()\ndt2 = (t1 - t0) / Ne\nprint(f\"Second execution took {dt2*1.e3:.2f} ms\")\n\nOn a donc gagné du temps avec le jit et ce malgré le fait que notre fonction est très simple et donc très optimisée à la base. Cette tendance sera amplifiée sur des calculs lourds sur GPU/TPU.\n\n","type":"content","url":"/intro-to-jax#compiler-avec-jit","position":13},{"hierarchy":{"lvl1":"Introduction","lvl3":"Autres transformations","lvl2":"Les transformations"},"type":"lvl3","url":"/intro-to-jax#autres-transformations","position":14},{"hierarchy":{"lvl1":"Introduction","lvl3":"Autres transformations","lvl2":"Les transformations"},"content":"Les autres transformations ne sont pas cruciales maintenant alors je les passe sous couvert. Mais elles sont ultra intéressantes dans d’autres cas, surtout grad.\n\n# WIP\n\n","type":"content","url":"/intro-to-jax#autres-transformations","position":15},{"hierarchy":{"lvl1":"Introduction","lvl2":"Liste non exhaustive des limitations de Jax"},"type":"lvl2","url":"/intro-to-jax#liste-non-exhaustive-des-limitations-de-jax","position":16},{"hierarchy":{"lvl1":"Introduction","lvl2":"Liste non exhaustive des limitations de Jax"},"content":"Forcément, cette belle promesse vient avec pas mal de limitations.","type":"content","url":"/intro-to-jax#liste-non-exhaustive-des-limitations-de-jax","position":17},{"hierarchy":{"lvl1":"Introduction","lvl3":"Les structures de contrôle","lvl2":"Liste non exhaustive des limitations de Jax"},"type":"lvl3","url":"/intro-to-jax#les-structures-de-contr-le","position":18},{"hierarchy":{"lvl1":"Introduction","lvl3":"Les structures de contrôle","lvl2":"Liste non exhaustive des limitations de Jax"},"content":"On commence par une des plus agacentes au début, les structures de contrôle. Fini les if, foret while.\n\nEn fait, ces dernières ne sont pas claires dans leurs buts et peuvent correspondre à plusieurs objectifs. Jax fournit donc des outils de remplacements qui ne manqueront pas de vous énerver (parfois). A titre d’exemple, forsera remplacée alternativement selon les buts par vmap, scan, where, lax.fori_loop ou pourra rester for dans ces bien choisis.\n\n","type":"content","url":"/intro-to-jax#les-structures-de-contr-le","position":19},{"hierarchy":{"lvl1":"Introduction","lvl3":"L’allocation dynamique de mémoire","lvl2":"Liste non exhaustive des limitations de Jax"},"type":"lvl3","url":"/intro-to-jax#lallocation-dynamique-de-m-moire","position":20},{"hierarchy":{"lvl1":"Introduction","lvl3":"L’allocation dynamique de mémoire","lvl2":"Liste non exhaustive des limitations de Jax"},"content":"Dans le monde de jax, il est interdit d’allouer dynamiquement de la mémoire, par exemple en créant des array de taille inconnue à la compilation. Cela ne manquera pas de vous créer des frustrations. On verra aussi qu’il est possible de trouver des compromis sur ce point. Le chapitre des sharp bits et globalement toutes les prises de parole de JakeVPD et Patrick Kidger mérite d’être lues pour comprendre la parole sainte à ce sujet.\n\nExemple:\n\ndef dumb_func_allocating_memory(n):\n    a = jnp.arange(n)\n    return a\n\n# jax.make_jaxpr(dumb_func_allocating_memory)(2) # Uncommment to see the error.\n\n\n\nConcretizationTypeError                   Traceback (most recent call last)\nCell In[11], line 1\n----> 1 jax.make_jaxpr(dumb_func_allocating_memory)(2)[... skipping hidden 14 frame]\n\nCell In[10], line 2, in dumb_func_allocating_memory(n)\n1 def dumb_func_allocating_memory(n):\n----> 2     a = jnp.arange(n)\n3     return a\n\nFile ~/miniforge3/envs/science/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:5947, in arange(start, stop, step, dtype, device, out_sharding)\n5945 if sharding is None or not sharding._is_concrete:\n5946   assert sharding is None or isinstance(sharding, NamedSharding)\n-> 5947   return _arange(start, stop=stop, step=step, dtype=dtype,\n5948                  out_sharding=sharding)\n5949 else:\n5950   output = _arange(start, stop=stop, step=step, dtype=dtype)\n\nFile ~/miniforge3/envs/science/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:5962, in _arange(start, stop, step, dtype, out_sharding)\n5960 util.check_arraylike(“arange”, start)\n5961 if stop is None and step is None:\n-> 5962   start = core.concrete_or_error(None, start, “It arose in the jnp.arange argument ‘stop’”)\n5963 else:\n5964   start = core.concrete_or_error(None, start, “It arose in the jnp.arange argument ‘start’”)\n\nFile ~/miniforge3/envs/science/lib/python3.12/site-packages/jax/_src/core.py:1847, in concrete_or_error(force, val, context)\n1845 maybe_concrete = val.to_concrete_value()\n1846 if maybe_concrete is None:\n-> 1847   raise ConcretizationTypeError(val, context)\n1848 else:\n1849   return force(maybe_concrete)\n\nConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: traced array with shape int32[]\nIt arose in the jnp.arange argument ‘stop’\nThe error occurred while tracing the function dumb_func_allocating_memory at /var/folders/67/hblp6z8n36ldk_9_bl9g80kh0000gn/T/ipykernel_50677/3347747001.py:1 for jit. This concrete value was not available in Python because it depends on the value of the argument n.\n\nSee \n\nhttps://​docs​.jax​.dev​/en​/latest​/errors​.html​#jax​.errors​.ConcretizationTypeError\n\nFrustration, colère ...\n\nDans un tel, cas il faut généralement se demander si on a vraiment besoin que nsoit dynamique. Si c’est vraiment le cas, alors on peut le rendre statique (au sens jax) en spécifiant:\n\nimport numpy as np\n\n\ndef make_dumb_function_allocating_memory(n):\n    def dumb_func_allocating_memory2(a):\n        x = a * jnp.arange(n)\n        return x\n\n    return dumb_func_allocating_memory2\n\n\ndfam = jax.jit(make_dumb_function_allocating_memory(3))\n\njax.make_jaxpr(dfam)(2)","type":"content","url":"/intro-to-jax#lallocation-dynamique-de-m-moire","position":21},{"hierarchy":{"lvl1":"Des ODE avec Jax ?"},"type":"lvl1","url":"/ode-with-jax","position":0},{"hierarchy":{"lvl1":"Des ODE avec Jax ?"},"content":"%matplotlib ipympl\nimport numpy as np\nimport jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nfrom jax import jit, vmap\nfrom dataclasses import dataclass\nfrom jax.tree_util import register_dataclass\nfrom diffrax import ODETerm, Dopri5, SaveAt, PIDController, diffeqsolve\n\njax.config.update(\"jax_enable_x64\", True)\n\n","type":"content","url":"/ode-with-jax","position":1},{"hierarchy":{"lvl1":"Des ODE avec Jax ?","lvl2":"Problème"},"type":"lvl2","url":"/ode-with-jax#probl-me","position":2},{"hierarchy":{"lvl1":"Des ODE avec Jax ?","lvl2":"Problème"},"content":"On s’intéresse à une paire d’oscillateurs linéaires couplés par une raideur K_{12}.\nOn voudrait trouver un régime permanent de manière simple, par exemple en simulant quelques périodes d’excitation.\n\nL’équation différentielle est:\\left \\lbrace \n\\begin{split}\nM_1  \\ddot x_1 + D_1  \\dot x_1 + K_1  x_1 + K_{12} (x_1 - x_2) = F_{d1} \\sin (w_d t)  \\\\\nM_2  \\ddot x_2 + D_2  \\dot x_2 + K_2  x_1 + K_{12} (x_2 - x_1) = F_{d2} \\sin (w_d t) \n\\end{split}\n\\right .\n\nOn divise par les masses et on introduit:\\varepsilon_1 = \\sqrt{\\dfrac{K_{12}}{K_1}}\n\net\\varepsilon_2 = \\sqrt{\\dfrac{K_{12}}{K_2}}\n\nOn obtient:\\left \\lbrace \n\\begin{split}\n\\ddot x_1 + \\frac{\\omega_{01}}{Q_1}  \\dot x_1 + \\omega_{01}^2  x_1 + \\varepsilon_{1}^2 \\omega_{01}^2 (x_1 - x_2) = A_{d1} \\sin (\\Omega w_0 t)  \\\\\n\\ddot x_2 + \\frac{\\omega_{02}}{Q_2}  \\dot x_2 + \\omega_{02}^2  x_2 + \\varepsilon_{2}^2 \\omega_{02}^2 (x_2 - x_1) = A_{d2} \\sin (\\Omega w_0 t) \n\\end{split}\n\\right .\n\nEt d’un point de vue physique, on voudrait connaitre les énergies dissipées par les amortissements D_1 et D_2 en régime permanent.\n\nNote\n\nOn fait quelques hypothèses simplificatrices:\\left\\lbrace\n\\begin{split}\nM_1 = M_2 = M \\\\\nQ_1 = Q_2 = Q \\\\\n\\omega_{02} = r \\omega_{01} = r \\omega_0 \\\\\nA_{d2} = \\beta A_{d1} =  \\beta A \\\\\n\\omega_d = \\Omega \\omega_0  \\\\\n\\varepsilon_1 = r \\varepsilon_2 = \\varepsilon \n\\end{split}\n\\right .\n\nLe problème se traduit alors par:\\left \\lbrace \n\\begin{split}\n\\ddot x_1 + \\frac{\\omega_{0}}{Q}  \\dot x_1 + \\omega_{0}^2  x_1 + \\varepsilon^2 \\omega_{0}^2 (x_1 - x_2) = A\\sin (w_d t)  \\\\\n\\ddot x_2 + r\\frac{\\omega_{0}}{Q}  \\dot x_2 + r^2 \\omega_{0}^2  x_2 + \\varepsilon^2 \\omega_{0}^2 (x_2 - x_1) = \\beta A \\sin (w_d t) \n\\end{split}\n\\right .\n\nLes variables du problème et leurs valeurs typiques sont donc:\\left \\lbrace \n\\begin{split}\n\\omega_0 = 200 \\pi \\\\\nQ = 50 \\\\\nA = 1 \\\\\nr = 1 \\\\\n\\varepsilon = 1 \\\\\n\\beta = 1 \\\\\n\\Omega = 1\n\\end{split}\n\\right .\n\nOn la traduit comme suit en Python:\n\nOn crée une classe pour stocker les paramètres du problème. C’est une solution assez pratique pour éviter de passer trop d’arguments à l’ODE et on peut gérer ça de manière transparente avec Jax.\n\n@register_dataclass\n@dataclass\nclass CoupledLinearResonatorParams:\n    \"\"\"\n    Parameters for the coupled linear resonator ODE system.\n    \"\"\"\n\n    w0: float = 200.0 * jnp.pi  # Natural frequency\n    Q: float = 50.0  # Quality factor\n    A: float = 1.0  # Amplitude of driving force\n    r: float = 1.0  # Frequency ratio\n    epsilon: float = 1.0  # Coupling factor\n    beta: float = 1.0  # Excitation ratio\n    W: float = 1.0  # Exctiation frequency factor\n\n\node_params = CoupledLinearResonatorParams()\node_params\n\nOn écrit l’ODE:\n\ndef coupled_linear_resonator_ode(t, X, params: CoupledLinearResonatorParams):\n    \"\"\"\n    ODE system for coupled linear resonators.\n    \"\"\"\n    x1, v1, x2, v2, E1, E2 = X\n    w0 = params.w0\n    Q = params.Q\n    A = params.A\n    r = params.r\n    epsilon = params.epsilon\n    beta = params.beta\n    W = params.W\n    dx1dt = v1\n    dv1dt = (\n        -(w0**2) * x1\n        - epsilon * w0**2 * (x1 - x2)\n        - w0 / Q * v1\n        + A * jnp.sin(W * w0 * t)\n    )\n    dx2dt = v2\n    dv2dt = (\n        -(r**2) * w0**2 * x2\n        - epsilon * w0**2 * (x2 - x1)\n        - r * w0 / Q * v2\n        + beta * A * jnp.sin(W * w0 * t)\n    )\n    P1 = v1**2 * w0 / Q\n    P2 = v2**2 * r * w0 / Q\n    return jnp.array([dx1dt, dv1dt, dx2dt, dv2dt, P1, P2])\n\n\nX0 = jnp.array(\n    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n)  # Initial state: [x1, v1, x2, v2, E1, E2]\nt = 0.2  # Initial time\ncoupled_linear_resonator_ode(t, X0, ode_params)\n\nOk, notre ODE fonctionne.\n\nEssayons de l’intégrer:\n\nterm = ODETerm(coupled_linear_resonator_ode)  # Define the ODE term\nsolver = Dopri5()  # Choose the Dormand-Prince 5(4) solver\nt0 = 0.0  # Initial time\nt1 = 2.0  # Final time\node_params = CoupledLinearResonatorParams(\n    w0=200.0 * jnp.pi,\n    Q=50.0,\n    A=1.0,\n    r=1.0,\n    epsilon=0.1,\n    beta=1.0,\n    W=1.0,\n)\nsaveat = SaveAt(\n    ts=jnp.linspace(t0, t1, 10000)\n)  # Specify time points to save the solution\nstepsize_controller = PIDController(rtol=1e-5, atol=1e-5)\nsol = diffeqsolve(\n    term,\n    solver,\n    t0=t0,\n    t1=t1,\n    dt0=0.1,\n    y0=X0,\n    saveat=saveat,\n    stepsize_controller=stepsize_controller,\n    args=ode_params,\n)\nt = np.array(sol.ts)\nx1 = np.array(sol.ys[:, 0])\nv1 = np.array(sol.ys[:, 1])\nx2 = np.array(sol.ys[:, 2])\nv2 = np.array(sol.ys[:, 3])\nE1 = np.array(sol.ys[:, 4])\nE2 = np.array(sol.ys[:, 5])\n\nplt.figure()\nplt.plot(t, x1)\nplt.grid()\nplt.title(\"Displacement of Resonator 1\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Displacement (m)\")\nplt.show()\n\nOk cela fonctionne, on peut donc construire une fonction qui fait la tâche demandée:\n\n@register_dataclass\n@dataclass\nclass CalculateSteadyStatePowerParams:\n    t0: float = 0.0\n    t1: float = 2.0\n    max_steps: int = 1000000\n\n\ndef calculate_steady_state_power(\n    X0,\n    ode_params: CoupledLinearResonatorParams,\n    calc_params: CalculateSteadyStatePowerParams,\n):\n    \"\"\"\n    Calculate the steady-state power dissipated by each resonator.\n\n        A tuple containing the steady-state power dissipated by resonator 1 and resonator\n    \"\"\"\n    term = ODETerm(coupled_linear_resonator_ode)  # Define the ODE term\n    solver = Dopri5()  # Choose the Dormand-Prince 5(4) solver\n    t0 = calc_params.t0  # Initial time\n    t1 = calc_params.t1  # Final time\n    Td = 2 * jnp.pi / ode_params.w0 * ode_params.W  # Driving period\n    t2 = t1 + Td\n\n    saveat0 = SaveAt(ts=[t0, t1])  # Specify time points to save the solution\n    stepsize_controller = PIDController(rtol=1e-7, atol=1e-7)\n    sol0 = diffeqsolve(\n        term,\n        solver,\n        t0=t0,\n        t1=t1,\n        dt0=0.01,\n        y0=X0,\n        saveat=saveat0,\n        stepsize_controller=stepsize_controller,\n        max_steps=calc_params.max_steps,\n        args=ode_params,\n    )\n    X1 = sol0.ys[-1]  # State at time t1\n    X1 = X1.at[4:].set(0.0)  # Reset accumulated power to zero\n    saveat1 = SaveAt(ts=[t1, t2])  # Specify time points to save the solution\n    stepsize_controller = PIDController(rtol=1e-7, atol=1e-7)\n    sol1 = diffeqsolve(\n        term,\n        solver,\n        t0=t1,\n        t1=t2,\n        dt0=0.01,\n        y0=X1,\n        saveat=saveat1,\n        stepsize_controller=stepsize_controller,\n        max_steps=calc_params.max_steps,\n        args=ode_params,\n    )\n    X2 = sol1.ys[-1]  # State at time t2\n    P = (X2[4:]) / Td  # Average power dissipated over one period\n    return P\n\n\nP = calculate_steady_state_power(\n    X0, ode_params, CalculateSteadyStatePowerParams(t0=0.0, t1=2.0)\n)\nP\n\nOn peut donc calculer les puissances en régime établi pour les 2 oscillateurs.\nFaisons maintenant une étude paramétrique avec vmap:\n\nrv = jnp.linspace(0.0, 2.0, 20)\nepsilonv = jnp.linspace(0.004, 0.08, 20)\n\nvcalc_steady_state_power = vmap(\n    vmap(\n        calculate_steady_state_power,\n        in_axes=(\n            None,\n            CoupledLinearResonatorParams(\n                w0=None,\n                Q=None,\n                A=None,\n                r=0,\n                epsilon=None,\n                beta=None,\n                W=None,\n            ),\n            None,\n        ),\n    ),\n    in_axes=(\n        None,\n        CoupledLinearResonatorParams(\n            w0=None,\n            Q=None,\n            A=None,\n            r=None,\n            epsilon=0,\n            beta=None,\n            W=None,\n        ),\n        None,\n    ),\n)\node_params2 = CoupledLinearResonatorParams(\n    w0=200.0 * jnp.pi,\n    Q=50.0,\n    A=1.0,\n    r=rv,\n    epsilon=epsilonv,\n    beta=1.0,\n    W=1.0,\n)\ncalc_params2 = CalculateSteadyStatePowerParams(t0=0.0, t1=2.0)\nP2 = vcalc_steady_state_power(X0, ode_params2, calc_params2)\nP2.shape\n\ncmap = \"jet\"\nfig = plt.figure(figsize=(12, 6))\nax0 = fig.add_subplot(131)\nplt.contourf(rv, epsilonv, P2[:, :, 0].T * 1.0e3, levels=20, cmap=cmap)\nplt.colorbar(label=\"P1 [mW/kg]\", orientation=\"horizontal\")\nplt.contour(\n    rv, epsilonv, P2[:, :, 0].T * 1.0e3, levels=20, colors=\"black\", linewidths=0.5\n)\nplt.xlabel(\"r\")\nplt.ylabel(\"epsilon\")\nplt.grid()\nax1 = fig.add_subplot(132)\nplt.contourf(rv, epsilonv, P2[:, :, 1].T * 1.0e3, levels=20, cmap=cmap)\nplt.colorbar(label=\"P2 [mW/kg]\", orientation=\"horizontal\")\nplt.contour(\n    rv, epsilonv, P2[:, :, 1].T * 1.0e3, levels=20, colors=\"black\", linewidths=0.5\n)\nplt.xlabel(\"r\")\n# plt.ylabel(\"epsilon\")\nplt.grid()\nax1 = fig.add_subplot(133)\nplt.contourf(\n    rv, epsilonv, (P2[:, :, 1].T + P2[:, :, 0].T) * 1.0e3, levels=20, cmap=cmap\n)\nplt.colorbar(label=\"P1 + P2 [mW/kg]\", orientation=\"horizontal\")\nplt.contour(\n    rv,\n    epsilonv,\n    (P2[:, :, 1].T + P2[:, :, 0].T) * 1.0e3,\n    levels=20,\n    colors=\"black\",\n    linewidths=0.5,\n)\nplt.xlabel(\"r\")\n# plt.ylabel(\"epsilon\")\nplt.grid()\nplt.show()\n\nC’est beau mais assez étrange. A discuter !","type":"content","url":"/ode-with-jax#probl-me","position":3}]}